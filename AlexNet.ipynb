{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLl2x9rC2Ngh"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8svkq8oK2WHG"
      },
      "source": [
        "# **Importing Libraries**\n",
        "Libraries included:\n",
        "\n",
        "\n",
        "*   Numpy\n",
        "*   Pandas\n",
        "*   MatPlotLib\n",
        "*   TensorFlow\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aa7mGMxz83O"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import PIL\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFo6rv5V969-"
      },
      "source": [
        "## **Loading Data and Typecasting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXShM1fwh7bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba837c7-6c32-4d80-e4e0-55b568abcb58"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z16APqFA7ZEw",
        "outputId": "080a1c56-3059-4c5c-9503-6aba93c77888"
      },
      "source": [
        "print(np.ptp(x_train))\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255\n",
            "(50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-UQf4wG9f-N",
        "outputId": "ffc7581a-5707-4be6-ef94-df301edf2b7c"
      },
      "source": [
        "m_train = x_train.shape[0]\n",
        "m_test = x_test.shape[0]\n",
        "\n",
        "print(\"Training Data Size =\", m_train)\n",
        "print(\"Test Data Size =\", m_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Size = 50000\n",
            "Test Data Size = 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlz9s76u-Jz5"
      },
      "source": [
        "# Creating training sets and normalizing\n",
        "norm_X = np.linalg.norm(x_train, ord = 2, axis = 0)\n",
        "x_train = x_train / norm_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9HdNzWlL1X8",
        "outputId": "4d8160f3-2d39-432e-c1a9-cf2cf7879057"
      },
      "source": [
        "print(np.ptp(x_train))\n",
        "print(np.ptp(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.009820172925945007\n",
            "255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_nK98Sw-4B9"
      },
      "source": [
        "# Creating training sets and normalizing\n",
        "norm_X = np.linalg.norm(x_test, ord = 2, axis = 0)\n",
        "x_test = x_test / norm_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8tFrDlnMBZo",
        "outputId": "5259f1a3-5f63-4843-a1c9-9d1d98f4730e"
      },
      "source": [
        "print(\"Shape of X test set:\", x_test.shape)\n",
        "print(\"Shape of Y test set:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X test set: (10000, 32, 32, 3)\n",
            "Shape of Y test set: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STTkMwvKybiC"
      },
      "source": [
        "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#training = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "#testing = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "#training = training.cache()\n",
        "#training = training.prefetch(AUTOTUNE)\n",
        "#training = aug(training)\n",
        "\n",
        "#testing = testing.prefetch(AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhZfE2_y8m_Q"
      },
      "source": [
        "class DataAugmentation:\n",
        "\n",
        "    # Function to translate the image in either of 4 directions by a fixed number of pixels\n",
        "    def img_translation(img, shift = 5, direction = 'right', roll = True):\n",
        "        assert direction in ['right', 'left', 'up', 'down'], \"Shift direction must be right, left, up or down\"\n",
        "\n",
        "        if direction == 'right' or 'left':\n",
        "            assert shift < img.shape[0], \"Shift must be smaller than width\"\n",
        "\n",
        "        if direction == 'up' or 'down':\n",
        "            assert shift < img.shape[1], \"Shift must be smaller than height\"\n",
        "\n",
        "        img = img.copy()\n",
        "        if direction == 'right':\n",
        "            slice = img[:, -shift:].copy()\n",
        "            img[:, shift:] = img[:, :-shift]\n",
        "            if roll:\n",
        "                img[:, :shift] = slice\n",
        "\n",
        "        if direction == 'left':\n",
        "            slice = img[:, :shift].copy()\n",
        "            img[:, :-shift] = img[:, shift:]\n",
        "            if roll:\n",
        "                img[:, -shift:] = slice\n",
        "\n",
        "        if direction == 'up':\n",
        "            slice = img[:shift, :].copy()\n",
        "            img[:-shift, :] = img[shift:, :]\n",
        "            if roll:\n",
        "                img[-shift:, :] = slice\n",
        "\n",
        "        if direction == 'down':\n",
        "            slice = img[-shift:, :].copy()\n",
        "            img[shift:, :] = img[:-shift, :]\n",
        "            if roll:\n",
        "                img[:, :shift] = slice\n",
        "\n",
        "        return img\n",
        "\n",
        "    # Function to crop out a random fixed sized patch of the image\n",
        "    def random_patch(img, crop_size = (27, 27)):\n",
        "        assert crop_size[0] < img.shape[0] and crop_size < img.shape[1], \"Crop size should be smaller than image size\"\n",
        "\n",
        "        img = img.copy()\n",
        "\n",
        "        w, h = img.shape[:2]\n",
        "        x, y = np.random.randint(h - crop_size[0], w - crop_size[1])\n",
        "\n",
        "        img = img[y:y + crop_size[0], x:x + crop_size[1]]\n",
        "\n",
        "        return img    \n",
        "\n",
        "    # Funciton to change the colour of the image by reducing intensity of one of the channels\n",
        "    def colour_change(img, colour_channel = 'r', ratio = 0.5):\n",
        "        assert colour_channel in 'rgb', \"Colour channel must be r, g or b\"\n",
        "        assert ratio < 1.0 and ratio >= 0.0, \"Ratio must be greater than equal to 0.0 and less than 1.0\"\n",
        "\n",
        "        img = img.copy()\n",
        "        idx = 'rgb'.index(colour_channel)\n",
        "        img[:, :, idx] = img[:, :, idx] * ratio\n",
        "\n",
        "        return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "_w_vbcdU30sa",
        "outputId": "40f27d9b-611b-4bcd-d268-0f562a6debf4"
      },
      "source": [
        "plt.figure(figsize = (1, 1))\n",
        "img_temp = DataAugmentation.img_translation(x_train[4])\n",
        "img_temp = DataAugmentation.colour_change(img_temp, colour_channel = 'b')\n",
        "plt.imshow(img_temp * 255.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe96ff2ad90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZrE5ema_HKL"
      },
      "source": [
        "def custom_aug(img, label):\n",
        "    img_temp1 = DataAugmentation.img_translation(img, direction = 'right')\n",
        "    img_temp2 = DataAugmentation.img_translation(img, direction = 'up')\n",
        "    img_temp3 = DataAugmentation.colour_change(img, colour_channel = 'r')\n",
        "    img_temp4 = DataAugmentation.colour_change(img, colour_channel = 'g')    \n",
        "    img_temp5 = DataAugmentation.colour_change(img, colour_channel = 'b')\n",
        "\n",
        "    aug = [img_temp1, img_temp2, img_temp3, img_temp4, img_temp5]\n",
        "    aug_label = [label, label, label, label, label]\n",
        "    aug = np.array(aug)\n",
        "    aug_label = np.array(aug_label)\n",
        "\n",
        "    return aug, aug_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMNzx3NG-zgH"
      },
      "source": [
        "aug_img, aug_label = custom_aug(x_train[100], y_train[100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TySG1GwmSVbJ"
      },
      "source": [
        "aug_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-3tJlNZfcHg",
        "outputId": "0ca0f2f6-9e48-4d6e-bce6-3c8782290661"
      },
      "source": [
        "for i in range(3000):\n",
        "    idx = np.random.randint(0, 50001)\n",
        "    aug_img, aug_label = custom_aug(x_train[idx], y_train[idx])\n",
        "    if i == 0:\n",
        "        x_aug = aug_img\n",
        "        x_aug_label = aug_label\n",
        "    else:\n",
        "        x_aug = np.append(x_aug, aug_img, axis = 0)\n",
        "        x_aug_label = np.append(x_aug_label, aug_label, axis = 0)\n",
        "    \n",
        "print(x_aug.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aL-oAYpl3KJ",
        "outputId": "338a9fba-f2df-4f6e-9755-9b0ae9266df8"
      },
      "source": [
        "x_train_aug = np.append(x_train, x_aug, axis = 0)\n",
        "y_train_aug = np.append(y_train, x_aug_label, axis = 0)\n",
        "\n",
        "print(x_train_aug.shape)\n",
        "print(y_train_aug.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(65000, 32, 32, 3)\n",
            "(65000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXI285Vh5Klh"
      },
      "source": [
        "# **Using TensorFlow**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXznwknHDt_g"
      },
      "source": [
        "### Fully Connected Network with only Dense Connections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDwlewEn87DX"
      },
      "source": [
        "def adjacent_sum(a, i, n):\n",
        "  j1 = max(0, int(i - (n / 2)))\n",
        "  j2 = min(a.shape[3] - 1, int(i + (n / 2)))\n",
        "  sum = np.zeros((a.shape[0], a.shape[1], a.shape[2]))\n",
        "\n",
        "  for j in range(j1, j2 + 1):\n",
        "    sum += np.square(a[:, :, :, j])\n",
        "\n",
        "  return sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGjI62UIkgOe"
      },
      "source": [
        "def response_norm2(a, k = 2, alpha_response_norm = 0.0001, beta_response_norm = 0.75, n = 5):\n",
        "    x = tf.nn.local_response_normalization(a, depth_radius = n, bias = k, alpha= alpha_response_norm, beta= beta_response_norm)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETz2dsdQCjAZ"
      },
      "source": [
        "def response_norm(a, k = 2, alpha_response_norm = 0.0001, beta_response_norm = 0.75, n = 5):\n",
        "  d = np.zeros(a.shape)\n",
        "  for i in range(0, a.shape[2]):\n",
        "    d[:, :, i] = a[:, :, i] / ((k + (alpha_response_norm * adjacent_sum(a, i, n))) ** beta_response_norm)\n",
        "\n",
        "  return d\n",
        "\n",
        "\n",
        "#k = 2\n",
        "#alpha_response_norm = 0.0001\n",
        "#beta_response_norm = 0.75\n",
        "#n = 5\n",
        "#d = np.zeros(b.shape)\n",
        "#for i in range(0, b.shape[3]):\n",
        "#  d[:, :, :, i] = b[:, :, :, i] / ((k + (alpha_response_norm * adjacent_sum(b, i, n))) ** beta_response_norm)\n",
        "\n",
        "#print(d)\n",
        "#print(d.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsXIvDKHdf0L",
        "outputId": "33711e32-7293-4984-df62-5e4068113138"
      },
      "source": [
        "a = np.random.randn(2, 5, 5, 3)\n",
        "b = layers.Conv2D(4, 3)(a)\n",
        "b = keras.activations.relu(b)\n",
        "print(b)\n",
        "print(\"__________________________________________________________________________\")\n",
        "print(\"__________________________________________________________________________\")\n",
        "print(\"__________________________________________________________________________\")\n",
        "c = response_norm2(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0.         0.3058603  0.55950135 0.39511937]\n",
            "   [0.         0.28819963 0.5649374  0.02023071]\n",
            "   [0.         0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         1.6963229 ]\n",
            "   [0.         0.27908647 0.6309761  0.10996975]\n",
            "   [0.         0.         1.0370772  0.        ]]\n",
            "\n",
            "  [[0.         0.         0.21197116 0.53569835]\n",
            "   [0.         0.48514602 0.73159903 0.        ]\n",
            "   [0.         0.         0.84013534 0.9731132 ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         0.35208234]\n",
            "   [0.06495925 0.8924943  0.46607724 0.95962   ]\n",
            "   [0.         1.0193843  0.44775498 0.18105882]]\n",
            "\n",
            "  [[0.         0.16540731 0.         0.2788244 ]\n",
            "   [0.02254814 0.7574839  1.0553511  0.        ]\n",
            "   [0.         0.         0.         0.7906439 ]]\n",
            "\n",
            "  [[0.         0.         0.82322973 0.        ]\n",
            "   [0.         0.         0.9535346  0.76042926]\n",
            "   [0.         0.01391336 0.61223584 0.2823662 ]]]], shape=(2, 3, 3, 4), dtype=float32)\n",
            "__________________________________________________________________________\n",
            "__________________________________________________________________________\n",
            "__________________________________________________________________________\n",
            "tf.Tensor(\n",
            "[[[[0.         0.18186179 0.33267447 0.23493443]\n",
            "   [0.         0.17136192 0.3359087  0.01202907]\n",
            "   [0.         0.         0.         0.        ]]\n",
            "\n",
            "  [[0.         0.         0.         1.0085309 ]\n",
            "   [0.         0.16594276 0.37517372 0.0653872 ]\n",
            "   [0.         0.         0.6166249  0.        ]]\n",
            "\n",
            "  [[0.         0.         0.12603725 0.3185242 ]\n",
            "   [0.         0.28846124 0.43499887 0.        ]\n",
            "   [0.         0.         0.4995165  0.5785807 ]]]\n",
            "\n",
            "\n",
            " [[[0.         0.         0.         0.20934844]\n",
            "   [0.03862219 0.53064173 0.27711102 0.570552  ]\n",
            "   [0.         0.60610056 0.266224   0.10765308]]\n",
            "\n",
            "  [[0.         0.09835139 0.         0.16578932]\n",
            "   [0.01340635 0.45037413 0.62747586 0.        ]\n",
            "   [0.         0.         0.         0.47010863]]\n",
            "\n",
            "  [[0.         0.         0.4894829  0.        ]\n",
            "   [0.         0.         0.56694347 0.45212874]\n",
            "   [0.         0.0082728  0.3640314  0.16789307]]]], shape=(2, 3, 3, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3R0q-Gy8-cV"
      },
      "source": [
        "### Using Model Sub-classing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuxEq8Uk9MJ0"
      },
      "source": [
        "class Dense(layers.Layer):\n",
        "  def __init__(self, out_channels):\n",
        "    super(Dense, self).__init__()\n",
        "    self.dense = layers.Dense(units = out_channels, activation = 'relu')\n",
        "    self.batchnorm = layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor):\n",
        "    x = self.dense(input_tensor)\n",
        "    x = self.batchnorm(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRfgfWh8GDhZ"
      },
      "source": [
        "class CNN5(layers.Layer):\n",
        "  def __init__(self, channels=96, kernel_size = 5, padding='valid', stride=1):\n",
        "    super(CNN5, self).__init__()\n",
        "    self.cnn = layers.Conv2D(filters=channels, kernel_size = kernel_size, strides=(stride, stride), padding=padding)\n",
        "    self.batchnorm = layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor):\n",
        "    x = self.cnn(input_tensor)\n",
        "    x = self.batchnorm(x)\n",
        "    #print(x.shape)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_bUOCZ8wYOh"
      },
      "source": [
        "class CNN3(layers.Layer):\n",
        "  def __init__(self, channels=256, kernel_size = 3, padding='valid', stride=1):\n",
        "    super(CNN3, self).__init__()\n",
        "    self.cnn = layers.Conv2D(filters=channels, kernel_size = kernel_size, strides=(stride, stride), padding=padding)\n",
        "    self.batchnorm = layers.BatchNormalization()\n",
        "\n",
        "  def call(self, input_tensor):\n",
        "    x = self.cnn(input_tensor)\n",
        "    x = self.batchnorm(x)\n",
        "    #print(x.shape)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-MaHBH_eZkq"
      },
      "source": [
        "class OverlappingPooling(layers.Layer):\n",
        "    def __init__(self, pool = 3, stride = 1):\n",
        "        super(OverlappingPooling, self).__init__()\n",
        "        self.pool = layers.MaxPooling2D(pool_size = (pool, pool), strides = stride)\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = self.pool(input_tensor)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjg8qjgxvyoF"
      },
      "source": [
        "def model():\n",
        "  INPUT = layers.Input(shape = (32, 32, 3))\n",
        "  \n",
        "  # Conv Layer 1\n",
        "  x = CNN5(channels=96)(INPUT)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = response_norm2(a = x)\n",
        "  x = OverlappingPooling(pool = 3, stride = 2)(x)\n",
        "  x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  # Conv Layer 2\n",
        "  x = CNN3(channels=256)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = response_norm2(a = x)\n",
        "  x = OverlappingPooling(pool = 3, stride = 1)(x)  \n",
        "  x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  # Conv Layer 3\n",
        "  x = CNN3(channels = 384, stride = 1)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "\n",
        "  # Conv Layer 4\n",
        "  x = CNN3(channels = 384, stride = 1)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "\n",
        "  # Conv Layer 5\n",
        "  x = CNN3(channels = 256, stride = 1)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = OverlappingPooling(pool = 3, stride = 1)(x)\n",
        "\n",
        "  # Dense Layer 1\n",
        "  x = layers.Flatten()(x)\n",
        "  x = Dense(out_channels = 1024)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "\n",
        "  # Dense Layer 2\n",
        "  x = Dense(out_channels = 1024)(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  OUTPUT = Dense(out_channels = 10)(x)\n",
        "\n",
        "  model = keras.Model(inputs = INPUT, outputs = OUTPUT)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdWDLTlAyEY2",
        "outputId": "48e85c45-f303-412b-d954-5bed2d386b63"
      },
      "source": [
        "my_model = model()\n",
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "cn_n5_1 (CNN5)               (None, 28, 28, 96)        7680      \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)    (None, 28, 28, 96)        0         \n",
            "_________________________________________________________________\n",
            "tf.nn.local_response_normali (None, 28, 28, 96)        0         \n",
            "_________________________________________________________________\n",
            "overlapping_pooling_1 (Overl (None, 13, 13, 96)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 13, 13, 96)        0         \n",
            "_________________________________________________________________\n",
            "cn_n3_1 (CNN3)               (None, 11, 11, 256)       222464    \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)    (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "tf.nn.local_response_normali (None, 11, 11, 256)       0         \n",
            "_________________________________________________________________\n",
            "overlapping_pooling_2 (Overl (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "cn_n3_2 (CNN3)               (None, 7, 7, 384)         886656    \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)    (None, 7, 7, 384)         0         \n",
            "_________________________________________________________________\n",
            "cn_n3_3 (CNN3)               (None, 5, 5, 384)         1329024   \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)    (None, 5, 5, 384)         0         \n",
            "_________________________________________________________________\n",
            "cn_n3_4 (CNN3)               (None, 3, 3, 256)         886016    \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)    (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "overlapping_pooling_3 (Overl (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              267264    \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              1053696   \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                10290     \n",
            "=================================================================\n",
            "Total params: 4,663,090\n",
            "Trainable params: 4,656,222\n",
            "Non-trainable params: 6,868\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i55NdY0wA0wF"
      },
      "source": [
        "my_model.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 0.01),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8hsL-4hBf3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eace846-07b7-452d-a148-0a1492cdf1dd"
      },
      "source": [
        "history1 = my_model.fit(x_train_aug, y_train_aug, batch_size = 128, epochs = 3, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "508/508 [==============================] - 1585s 3s/step - loss: 1.7253 - accuracy: 0.3634\n",
            "Epoch 2/3\n",
            "508/508 [==============================] - 1561s 3s/step - loss: 1.2630 - accuracy: 0.5485\n",
            "Epoch 3/3\n",
            "508/508 [==============================] - 1565s 3s/step - loss: 1.0624 - accuracy: 0.6260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiOCM2RYAif0",
        "outputId": "5c080f33-922a-4ed3-e572-d8752a56e869"
      },
      "source": [
        "my_model.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "history2 = my_model.fit(x_train_aug, y_train_aug, batch_size = 64, epochs = 5, initial_epoch = 3, shuffle = True, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5\n",
            "915/915 [==============================] - 1456s 2s/step - loss: 0.8798 - accuracy: 0.6935 - val_loss: 1.9513 - val_accuracy: 0.3928\n",
            "Epoch 5/5\n",
            "915/915 [==============================] - 1447s 2s/step - loss: 0.7874 - accuracy: 0.7248 - val_loss: 5.1755 - val_accuracy: 0.1125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A366sh1Z2Cx",
        "outputId": "e0bee01d-b443-4b09-aa42-c8bdf1452558"
      },
      "source": [
        "history3 = my_model.fit(x_train, y_train, batch_size = 128, epochs = 10, initial_epoch = 5, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10\n",
            "391/391 [==============================] - 1125s 3s/step - loss: 0.6200 - accuracy: 0.7865\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 1120s 3s/step - loss: 0.5586 - accuracy: 0.8093\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 1127s 3s/step - loss: 0.4933 - accuracy: 0.8305\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 1128s 3s/step - loss: 0.4265 - accuracy: 0.8555\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 1131s 3s/step - loss: 0.3774 - accuracy: 0.8677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlfOl8WOmsxr",
        "outputId": "b30c3ab2-bd1d-40d0-cc0f-1cf208f4f57b"
      },
      "source": [
        "my_model.save('/content/drive/MyDrive/Colab Notebooks/AlexNet/Model')\n",
        "\n",
        "acc = [0.] + history1.history['accuracy']\n",
        "\n",
        "loss = history1.history['loss']\n",
        "\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/AlexNet/acc', acc)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/AlexNet/loss', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_3_layer_call_and_return_conditional_losses, conv2d_3_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses, conv2d_4_layer_call_fn, conv2d_5_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/AlexNet/Model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/AlexNet/Model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9rV-17isMZh"
      },
      "source": [
        "my_model2 = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/AlexNet/Model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkU3dnJAsea2"
      },
      "source": [
        "my_model2.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVf1myg3iu_g",
        "outputId": "466ce401-8ed6-40f3-a5cc-c8e38bfc1680"
      },
      "source": [
        "history4 = my_model2.fit(x_train, y_train, batch_size = 128, epochs = 15, initial_epoch = 10, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15\n",
            "391/391 [==============================] - 1153s 3s/step - loss: 0.1799 - accuracy: 0.9419\n",
            "Epoch 12/15\n",
            "391/391 [==============================] - 1143s 3s/step - loss: 0.1055 - accuracy: 0.9684\n",
            "Epoch 13/15\n",
            "391/391 [==============================] - 1141s 3s/step - loss: 0.0791 - accuracy: 0.9763\n",
            "Epoch 14/15\n",
            "391/391 [==============================] - 1136s 3s/step - loss: 0.0602 - accuracy: 0.9823\n",
            "Epoch 15/15\n",
            "391/391 [==============================] - 1137s 3s/step - loss: 0.0547 - accuracy: 0.9834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jg8nwyTPVtm",
        "outputId": "70e56219-e1d3-4b6d-f127-3e4304793e6c"
      },
      "source": [
        "my_model2.save('/content/drive/MyDrive/Colab Notebooks/AlexNet/Model 2')\n",
        "\n",
        "\n",
        "acc += history4.history['accuracy']\n",
        "\n",
        "loss += history4.history['loss']\n",
        "\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/AlexNet', acc)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/AlexNet', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_2_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses, conv2d_3_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/AlexNet/Model 2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/AlexNet/Model 2/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO0hxyikPv5t"
      },
      "source": [
        "my_model3 = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/AlexNet/Model 2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9vigXprQNvd"
      },
      "source": [
        "my_model3.compile(\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2V-ATn_QCCT",
        "outputId": "913b86c4-a8ba-40c4-d834-89353562efed"
      },
      "source": [
        "history5 = my_model3.fit(x_train, y_train, batch_size = 128, epochs = 18, initial_epoch = 15, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/18\n",
            "391/391 [==============================] - 1190s 3s/step - loss: 0.0294 - accuracy: 0.9925\n",
            "Epoch 17/18\n",
            "391/391 [==============================] - 1192s 3s/step - loss: 0.0181 - accuracy: 0.9962\n",
            "Epoch 18/18\n",
            "391/391 [==============================] - 1181s 3s/step - loss: 0.0141 - accuracy: 0.9975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZJ0rh1Ty-X7",
        "outputId": "f2aa5c09-5e93-4a16-d9ae-afe120dd6103"
      },
      "source": [
        "my_model3.evaluate(x_test, y_test, batch_size = 128, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 51s 637ms/step - loss: 1.7724 - accuracy: 0.6230\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7723822593688965, 0.6230000257492065]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSDoAShOD3nF"
      },
      "source": [
        "### Data Augmentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPCwGVjMYfSt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}